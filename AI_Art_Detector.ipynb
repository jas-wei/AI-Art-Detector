{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2NTOTzpwjBKk"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "\n",
        "#import tqdm # this is for displaying a progress bar\n",
        "\n",
        "# Device Configuration\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')       #Use this for Windows, Google Colab\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')        #Use this for MacOS\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeP819wWxcsy"
      },
      "source": [
        "[View our dataset on Google Drive here](https://drive.google.com/drive/folders/1F1LxmTDe8oy9KEKCgCGSUMAZuHX4ebRJ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i8i8spMROK8L",
        "outputId": "1350198d-2db4-440f-90c7-8ffff46281eb"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# attemp to find corrupted images\n",
        "\n",
        "data_path = '../SENG_474_Dataset_Filtered'\n",
        "\n",
        "# Walk through all files in the folder\n",
        "for root, _, files in os.walk(data_path):\n",
        "    for fname in files:\n",
        "        file_path = os.path.join(root, fname)\n",
        "\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()  # Verify the file is a valid image\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Failed to load image: {file_path}\")\n",
        "            print(f\"        {type(e).__name__}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVMxUAZMnkzs"
      },
      "source": [
        "#Split data into train set, test set, validation set and their respective directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ApTstE2YjG7B",
        "outputId": "cd40d618-1b87-4a30-b800-ad2c1201e6b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'0-Human': 0, '1-AI': 1}\n",
            "Total images: 20000\n",
            "Training images: 12000\n",
            "Validation images: 4000\n",
            "Testing images: 4000\n"
          ]
        }
      ],
      "source": [
        "#Create Dataloaders and Preprocess Data\n",
        "#Based off of code from https://github.com/gaurav67890/Pytorch_Tutorials/blob/master/cnn-scratch-training.ipynb\n",
        "\n",
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((64,64)),       # TODO: decide what to modify this to\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),              # 0-255 to 0-1, numpy to tensors\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "\n",
        "#Path variables to data directory\n",
        "#data_path='/content/drive/MyDrive/SENG_474_Dataset_10k'       #Path on Google Drive\n",
        "data_path='../SENG_474_Dataset_10k'                            #Local Path\n",
        "\n",
        "# seed to keep random split the same each time\n",
        "seed = 42\n",
        "generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "full_dataset = torchvision.datasets.ImageFolder(data_path, transform=transformer)\n",
        "\n",
        "# 3-way split split\n",
        "train_size = int(0.6 * len(full_dataset))\n",
        "valid_size = int(0.2 * len(full_dataset))\n",
        "test_size = int(0.2 * len(full_dataset))\n",
        "\n",
        "#split the data\n",
        "train_dataset, valid_dataset, test_dataset = random_split(full_dataset, [train_size, valid_size, test_size], generator=generator)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=64,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0\n",
        "                          )\n",
        "\n",
        "valid_loader = DataLoader(valid_dataset,\n",
        "                          batch_size=64,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0\n",
        "                          )\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=64,\n",
        "                         shuffle=True,   # - falsed out shuffle for now, to keep evaluation deterministic? - kedan\n",
        "                         num_workers=0\n",
        "                         )\n",
        "\n",
        "#print to make sure classes were assigned correct label\n",
        "print(full_dataset.class_to_idx)\n",
        "\n",
        "#print number of images\n",
        "print(f\"Total images: {len(full_dataset)}\")\n",
        "print(f\"Training images: {len(train_dataset)}\")\n",
        "print(f\"Validation images: {len(valid_dataset)}\")\n",
        "print(f\"Testing images: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXSVLGTLG5dM"
      },
      "outputs": [],
      "source": [
        "#PyTorch Tutorial 14 - Convolutional Neural Network (CNN) by Patrick Loeber on YouTube\n",
        "# https://www.youtube.com/watch?v=pDdP0TFzsoQ\n",
        "\n",
        "def showImages(img):\n",
        "    #Show random images from the training set\n",
        "    img = img / 2 + 0.5 #unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "showImages(torchvision.utils.make_grid(images))\n",
        "\n",
        "conv1 = nn.Conv2d(3, 6, 5)\n",
        "pool = nn.MaxPool2d(2, 2)\n",
        "conv2 = nn.Conv2d(6, 16, 5)\n",
        "print(images.shape)\n",
        "x = conv1(images)\n",
        "x = pool(x)\n",
        "x = conv2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OU0g9z4jjIfy"
      },
      "outputs": [],
      "source": [
        "# Define Convolutional Neural Network model\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)       # output: [6, 64, 64]\n",
        "        self.pool = nn.MaxPool2d(2, 2)        # output: [6, 31, 31]\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)      # output: [16, 14, 14] after pool\n",
        "        self.fc1 = nn.Linear(16*14*14, 120)   # 120 -> 288? (20736/72)\n",
        "        self.fc2 = nn.Linear(120, 18)\n",
        "        self.fc3 = nn.Linear(18, 2)           # TODO: we can play with num of fc and nodes if we encounter under/overfitting\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # using relu for activation\n",
        "        # print(\"After conv1 + pool:\", x.shape)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # print(\"After conv2 + pool:\", x.shape)\n",
        "        x = x.view(-1, 16*14*14)                # flatten the tensor before passing it to fc????\n",
        "        # print(\"After flattening:\", x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt-OkTypjOHx",
        "outputId": "0469817c-e8da-4c6d-f842-80aa7bba82c4"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES=True\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Define hyper-parameters\n",
        "num_epochs = 8\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6)     # TODO: SGD or Adam??? comapre training results\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1, min_lr=1e-6)\n",
        "\n",
        "# storing metrics for all epoches\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "n_total_training_steps = len(train_loader)\n",
        "training_halfway = n_total_training_steps//2\n",
        "\n",
        "n_total_valid_steps = len(valid_loader)\n",
        "valid_halfway = n_total_valid_steps//2\n",
        "\n",
        "for epoch in range (num_epochs):\n",
        "    model.train()\n",
        "    #storing running total of loss for current epoch\n",
        "    training_running_loss_first = 0.0\n",
        "    training_running_loss_second = 0.0\n",
        "\n",
        "    valid_running_loss_first = 0.0\n",
        "    valid_running_loss_second = 0.0\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f'=== Epoch {epoch+1}: Current LR: {current_lr} ===')\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader): # TODO: it seems that we have few corrupted images\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward propagation\n",
        "        outputs = model(images) # predictions\n",
        "        train_loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward propagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()        # applied every batch\n",
        "\n",
        "        if i < training_halfway:\n",
        "            training_running_loss_first += train_loss.item()\n",
        "        else:\n",
        "            training_running_loss_second += train_loss.item()\n",
        "\n",
        "\n",
        "        # print out our model's performance every 50 iterations\n",
        "        if (i+1) % 50 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_training_steps}, Train_Loss: {train_loss.item():.4f}]')\n",
        "\n",
        "    \n",
        "    scheduler.step(train_loss) # applied every epoch\n",
        "\n",
        "    # store average loss for this epoch\n",
        "    train_losses.append(training_running_loss_first / training_halfway)\n",
        "    train_losses.append(training_running_loss_second / (n_total_training_steps - training_halfway))\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (images, labels) in enumerate(valid_loader):\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward propagation\n",
        "            outputs = model(images)\n",
        "            valid_loss = criterion(outputs, labels)\n",
        "\n",
        "            if i < valid_halfway:\n",
        "                valid_running_loss_first += valid_loss.item()\n",
        "            else:\n",
        "                valid_running_loss_second += valid_loss.item()\n",
        "\n",
        "\n",
        "            # print out our model's performance every 50 iterations\n",
        "            if i == 187:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_valid_steps}, Valid_Loss: {valid_loss.item():.4f}]')\n",
        "\n",
        "        valid_losses.append(valid_running_loss_first / valid_halfway)\n",
        "        valid_losses.append(valid_running_loss_second / (n_total_valid_steps - valid_halfway))\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "path = 'models/model2.pt' \n",
        "def save_model(model, path):\n",
        "  torch.save(model.state_dict(), path)  # saves model to a file\n",
        "\n",
        "# save_model(model, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yhkr_69gjRSu",
        "outputId": "ebd706d7-24e7-4b87-c25c-447102f8e48d"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "\n",
        "# Call this function in case you want to use an older model\n",
        "def load_model(path):\n",
        "      model = CNN()                      # create empty model\n",
        "      model.load_state_dict(torch.load(path))      # load a static dict with trained parameters from file to the model\n",
        "      model.eval()                                # set model to evaluation mode (was previously incorrectly set to train)\n",
        "      return model\n",
        "\n",
        "model.eval()  # might wanna do this to set model to evaluation mode -Jasmine\n",
        "with torch.no_grad():\n",
        "    all_pred_labels = []\n",
        "    all_labels = []\n",
        "\n",
        "    TP = 0\n",
        "    m_samples = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1) # max() returns (value, index)\n",
        "        m_samples += labels.size(0)\n",
        "        TP += (predicted == labels).sum().item()\n",
        "\n",
        "        # convert predicted and actual labels into numpy and add to lists\n",
        "        all_pred_labels.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # for evaluation we can only print accuracy since we have a perfectly balanced set\n",
        "    acc = 100.0 * TP / m_samples\n",
        "    print(f'Accuracy of predicting AI: {acc} %')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Lg5cNdsFjRKi",
        "outputId": "ec842cb3-89bd-46e8-cc07-e7463801bd21"
      },
      "outputs": [],
      "source": [
        "# compute accuracy, precision, recall, and f1\n",
        "accuracy = 100.0 * np.mean(np.array(all_pred_labels) == np.array(all_labels))\n",
        "precision = 100.0 * precision_score(all_labels, all_pred_labels, zero_division=0)\n",
        "recall = 100.0 * recall_score(all_labels, all_pred_labels, zero_division=0)\n",
        "f1 = 100.0 * f1_score(all_labels, all_pred_labels, zero_division=0)\n",
        "\n",
        "# print metrics first\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"Precision: {precision:.2f}%\")\n",
        "print(f\"Recall: {recall:.2f}%\")\n",
        "print(f\"F1 Score: {f1:.2f}%\")\n",
        "\n",
        "# bar chart for test metrics\n",
        "plt.figure(figsize=(6, 4))\n",
        "metrics = [accuracy, precision, recall, f1]\n",
        "labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "plt.bar(labels, metrics, color=['blue', 'red', 'green', 'purple'])\n",
        "plt.title('Test Performance Metrics')\n",
        "plt.ylabel('Percentage')\n",
        "plt.ylim(0, 100)\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n",
        "# plot loss vs epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "x_vals = [i / 2 for i in range(1, len(train_losses) + 1)]\n",
        "plt.plot(x_vals, train_losses, label='Training Loss (1st and 2nd Half per Epoch)', color='blue')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# plot confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_pred_labels)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['AI', 'Human'], yticklabels=['AI', 'Human'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AI_detector",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
